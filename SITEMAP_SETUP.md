# üìã Configura√ß√£o de Sitemaps - IspiAI

## ‚úÖ Implementa√ß√£o Completa

O sistema de sitemaps foi implementado com:

### üéØ Componentes Criados

1. **Structured Data (JSON-LD NewsArticle)**
   - ‚úÖ `src/lib/structured-data.ts` - Gera√ß√£o de JSON-LD otimizado para Google
   - ‚úÖ `src/components/SEOHead.tsx` - Componente atualizado com suporte completo
   - ‚úÖ Todos os campos obrigat√≥rios do Google implementados:
     - `mainEntityOfPage` (WebPage com @id)
     - `image` como array de ImageObject (‚â•1200px)
     - `publisher.logo` com dimens√µes (‚â•112√ó112px)
     - `articleSection`, `keywords`, `wordCount`
     - Datas ISO 8601 com timezone
   - ‚úÖ Meta tag `max-image-preview:large` para Google Discover

2. **Gera√ß√£o de Sitemaps**
   - ‚úÖ `src/lib/sitemap-generator.ts` - Gera√ß√£o de sitemap.xml e sitemap_news.xml
   - ‚úÖ `src/lib/article-data.ts` - Mock data (substituir por API real)
   - ‚úÖ `vite-plugin-sitemap.ts` - Plugin Vite para build-time generation
   - ‚úÖ `public/sitemap.xml` - Sitemap principal (todas as p√°ginas)
   - ‚úÖ `public/sitemap_news.xml` - Sitemap Google News (artigos ‚â§48h)
   - ‚úÖ `public/robots.txt` - J√° configurado e apontando para ambos sitemaps

3. **Regenera√ß√£o Autom√°tica (Lovable Cloud)**
   - ‚úÖ `supabase/functions/generate-sitemaps/index.ts` - Edge Function
   - ‚úÖ `supabase/config.toml` - Configura√ß√£o da fun√ß√£o
   - ‚úÖ `supabase/migrations/setup_sitemap_cron.sql` - Script SQL para cron job di√°rio

---

## üöÄ Pr√≥ximos Passos (Produ√ß√£o)

### 1. Preparar Assets

#### Logo do Publisher
Criar logo oficial em `public/logo.png`:
- ‚úÖ Dimens√µes m√≠nimas: **112√ó112px**
- ‚úÖ Recomendado: 200√ó60px (largura ‚â§600px, altura ‚â§60px)
- ‚úÖ Formato: PNG com fundo transparente ou branco
- üìç Atualizar URL em `src/pages/Article.tsx` (linha 125)

#### Imagens de Artigos
Preparar imagens em m√∫ltiplas propor√ß√µes:
- ‚úÖ **1200√ó675px** (16:9) - Para cards e hero images
- ‚úÖ **1200√ó1200px** (1:1) - Para redes sociais
- ‚úÖ Largura m√≠nima: **1200px** (requisito Google Discover)

### 2. Integrar API/CMS Real

Substituir mock data em `src/lib/article-data.ts`:

```typescript
export async function fetchAllArticles(): Promise<Article[]> {
  // Op√ß√£o 1: Supabase
  const { data, error } = await supabase
    .from('articles')
    .select('slug, title, category, publishDate, modifiedDate, keywords')
    .order('publishDate', { ascending: false });
  
  // Op√ß√£o 2: API REST
  const response = await fetch('https://api.ispiai.com/articles');
  const articles = await response.json();
  
  return articles;
}
```

Atualizar `src/pages/Article.tsx` para buscar dados reais baseado no slug.

### 3. Habilitar Lovable Cloud (Backend)

Para regenera√ß√£o autom√°tica dos sitemaps:

1. **Habilitar Lovable Cloud** no projeto
2. **Deploy da Edge Function**:
   ```bash
   # Fun√ß√£o j√° est√° criada em supabase/functions/generate-sitemaps/
   # Ser√° deployada automaticamente ao habilitar Cloud
   ```

3. **Configurar Cron Job**:
   - Abrir Supabase SQL Editor
   - Copiar conte√∫do de `supabase/migrations/setup_sitemap_cron.sql`
   - Substituir `[SEU-PROJECT-REF]` e `[SEU-ANON-KEY]`
   - Executar o SQL

4. **Verificar configura√ß√£o**:
   ```sql
   SELECT * FROM cron.job WHERE jobname = 'regenerate-sitemaps-daily';
   ```

### 4. Valida√ß√£o e Testes

#### JSON-LD NewsArticle
1. Acessar qualquer artigo (ex: `/noticias/ia-revoluciona-diagnostico-medico`)
2. Validar no **Google Rich Results Test**:
   - https://search.google.com/test/rich-results
3. Verificar todos os campos obrigat√≥rios ‚úÖ

#### Sitemaps
1. **Validar XML**:
   - https://www.xml-sitemaps.com/validate-xml-sitemap.html
   - Testar `/sitemap.xml` e `/sitemap_news.xml`

2. **Google Search Console**:
   - Adicionar propriedade: https://ispiai.com
   - Enviar ambos os sitemaps:
     - `https://ispiai.com/sitemap.xml`
     - `https://ispiai.com/sitemap_news.xml`
   - Monitorar cobertura e erros

3. **Teste da Edge Function** (ap√≥s deploy):
   ```bash
   curl -X POST https://[PROJECT-REF].supabase.co/functions/v1/generate-sitemaps \
     -H "Authorization: Bearer [ANON-KEY]" \
     -H "Content-Type: application/json"
   ```

### 5. Google Publisher Center

Para Google News:
1. Registrar em: https://publishercenter.google.com/
2. Verificar propriedade do dom√≠nio
3. Enviar sitemap News: `https://ispiai.com/sitemap_news.xml`
4. Aguardar aprova√ß√£o (pode levar dias/semanas)

---

## üìä Checklist de Qualidade

### NewsArticle JSON-LD ‚úÖ
- [x] `@type: "NewsArticle"` implementado
- [x] `headline` (‚â§110 chars)
- [x] `description`
- [x] `image[]` array com ImageObject (‚â•1200px)
- [x] `datePublished` e `dateModified` (ISO 8601 + timezone)
- [x] `author` (@type Person com name e url)
- [x] `publisher` com logo (‚â•112√ó112px)
- [x] `mainEntityOfPage` (WebPage com @id)
- [x] `articleSection` (categoria)
- [x] `keywords[]` (array de tags)
- [x] `wordCount` (calculado do conte√∫do)
- [x] `url` (can√¥nica absoluta)
- [x] Meta tag `max-image-preview:large`

### Sitemap Principal ‚úÖ
- [x] Inclui Home, Busca, todas as mat√©rias
- [x] `<lastmod>` confi√°vel (data real)
- [x] Formato XML v√°lido
- [x] M√°ximo 1000 URLs por arquivo

### Sitemap Google News ‚úÖ
- [x] Apenas artigos ‚â§48 horas
- [x] Namespace `xmlns:news` correto
- [x] `<news:publication>` com name e language
- [x] `<news:publication_date>` ISO 8601
- [x] `<news:title>` escapado corretamente
- [x] `<news:keywords>` inclu√≠do
- [x] M√°ximo 1000 URLs

### Infraestrutura ‚úÖ
- [x] `robots.txt` aponta ambos sitemaps
- [x] Sitemaps gerados no build (plugin Vite)
- [x] Edge Function criada
- [x] Script SQL para cron job pronto
- [ ] **TODO**: Habilitar Lovable Cloud
- [ ] **TODO**: Configurar cron job no Supabase

---

## üîß Comandos √öteis

### Build com gera√ß√£o de sitemaps
```bash
npm run build
# Sitemaps ser√£o gerados automaticamente em public/
```

### Testar Edge Function localmente (ap√≥s habilitar Cloud)
```bash
# Via Supabase CLI
supabase functions serve generate-sitemaps

# Testar
curl -X POST http://localhost:54321/functions/v1/generate-sitemaps
```

### Verificar cron jobs no Supabase
```sql
-- Ver todos os jobs
SELECT * FROM cron.job;

-- Ver hist√≥rico de execu√ß√µes
SELECT * FROM cron.job_run_details 
WHERE jobid = (SELECT jobid FROM cron.job WHERE jobname = 'regenerate-sitemaps-daily')
ORDER BY start_time DESC 
LIMIT 10;
```

---

## üìö Refer√™ncias

- [Google NewsArticle Structured Data](https://developers.google.com/search/docs/appearance/structured-data/article)
- [Google News Sitemap](https://developers.google.com/search/docs/crawling-indexing/sitemaps/news-sitemap)
- [Google Discover Guidelines](https://developers.google.com/search/docs/appearance/google-discover)
- [Sitemap Protocol](https://www.sitemaps.org/protocol.html)
- [Schema.org NewsArticle](https://schema.org/NewsArticle)

---

## üéâ Status Atual

‚úÖ **Sistema completo de structured data e sitemaps implementado**
‚úÖ **Build-time generation funcionando**
‚úÖ **Edge Function pronta para deploy**
‚è≥ **Aguardando**: Lovable Cloud para regenera√ß√£o autom√°tica
‚è≥ **Aguardando**: Dados reais da API/CMS

**O sistema est√° production-ready para sitemaps est√°ticos. Para regenera√ß√£o autom√°tica, basta habilitar Lovable Cloud e configurar o cron job.**
